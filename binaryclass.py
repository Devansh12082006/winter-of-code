# -*- coding: utf-8 -*-
"""Binaryclass.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V1VZuLrleoFD4LQsNCI-imS3bozqH_sV
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

a= pd.read_csv("/content/binary_classification_train.csv")

x_train=a.values[0:24000,1:21]
y_train=a.values[0:24000,21:22]

x_test=a.values[24000:48000,1:21]
y_test=a.values[24000:48000,21:22]


def sigmoid(z):
  g= 1/(1+np.exp(-z))
  return g

def compute_cost(x,y,w,b):
  m = x.shape[0]
  f_wb = sigmoid(np.matmul(x, w) + b)
  cost = (-1 / m) * (np.dot(y.T , np.log(f_wb)) + np.dot((1 - y).T, np.log(1 - f_wb)))
  cost = cost.item()
  return cost

def compute_gradient(x,y,w,b):
  m,n= x.shape
  dj_dw= np.zeros((n,1))
  dj_db=0
  f_wb=sigmoid(np.matmul(x,w)+b)
  dj_dw= np.matmul(x.T,(f_wb-y))
  dj_db=np.sum(f_wb-y)
  dj_dw=dj_dw/m
  dj_db=dj_db/m
  return dj_dw,dj_db

def gradient_descent(x,y,w,b,alpha,num_iterations):
   m,n=x.shape
   j_history=[]
   for i in range(num_iterations):
    dj_dw,dj_db= compute_gradient(x,y,w,b)
    w=w - alpha*dj_dw
    b=b-alpha*dj_db

    if i < num_iterations:
      j_history.append(compute_cost(x,y,w,b))

    if i%1000 ==0:
      print(f"Iteration {i:4d}: Cost {j_history[-1]}   ")
   return w,b,j_history

w=np.zeros((20,1))
b=0
w,b,j_history=gradient_descent(x_train,y_train,w,b,0.00022,10000)

print(f'w={w}')
print(f'b={b}')
w= [[ 3.88960052e-03],
 [-4.64948604e-04],
 [ 2.85571723e-04],
 [-1.00560447e-02],
 [ 5.96674003e-05],
 [ 1.82182097e-02],
 [ 1.67675421e-03],
 [ 2.22393323e-03],
 [ 2.07208991e-03],
 [ 6.92548715e-04],
 [-1.56627667e-03],
 [-3.82929597e-04],
 [-4.04195676e-03],
 [-1.69362106e-03],
 [ 3.54744856e-04],
 [-6.85115818e-03],
 [ 2.43132971e-02],
 [-1.13629131e-02],
 [ 1.16113310e-02],
 [ 9.31083156e-04]]

b= -0.00034184194060970835




def compute_f1_score(y_true, y_pred):

    TP = np.sum((y_true == 1) & (y_pred == 1))
    FP = np.sum((y_true == 0) & (y_pred == 1))
    FN = np.sum((y_true == 1) & (y_pred == 0))

    precision = TP / (TP + FP) if TP + FP != 0 else 0
    recall = TP / (TP + FN) if TP + FN != 0 else 0

    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall != 0 else 0
    return f1

y_predicted= sigmoid(np.matmul(x_test,w) + b)
for i in range(12000):
  if y_predicted[i]>=0.5:
    y_predicted[i]=1
  else:
    y_predicted[i]=0

f1 = compute_f1_score(y_test, y_predicted)
print(f'Test F1 Score: {f1:.4f}')

test=pd.read_csv("/content/binary_classification_test.csv")
x_test=test.values[0:12000,1:21]
print(x_test)
y_predicted= sigmoid(np.matmul(x_test,w) + b)
for i in range(12000):
  if y_predicted[i]>=0.5:
    y_predicted[i]=1
  else:
    y_predicted[i]=0
print(f'y_predicted={y_predicted}')
cost=compute_cost(x_test,y_predicted,w,b)
print(f'cost={cost}')



